{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 647ms/step - accuracy: 0.6334 - loss: 1.6801\n",
      "Epoch 2/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 667ms/step - accuracy: 0.7204 - loss: 0.8696\n",
      "Epoch 3/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 679ms/step - accuracy: 0.7226 - loss: 0.7908\n",
      "Epoch 4/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 655ms/step - accuracy: 0.7327 - loss: 0.7257\n",
      "Epoch 5/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 661ms/step - accuracy: 0.7339 - loss: 0.6897\n",
      "Epoch 6/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 662ms/step - accuracy: 0.7407 - loss: 0.6589\n",
      "Epoch 7/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 664ms/step - accuracy: 0.7454 - loss: 0.6440\n",
      "Epoch 8/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 667ms/step - accuracy: 0.7533 - loss: 0.6262\n",
      "Epoch 9/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 665ms/step - accuracy: 0.7533 - loss: 0.6203\n",
      "Epoch 10/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 671ms/step - accuracy: 0.7590 - loss: 0.6060\n",
      "Epoch 11/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 672ms/step - accuracy: 0.7631 - loss: 0.5954\n",
      "Epoch 12/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 668ms/step - accuracy: 0.7704 - loss: 0.5907\n",
      "Epoch 13/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 1s/step - accuracy: 0.7756 - loss: 0.5735\n",
      "Epoch 14/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.7810 - loss: 0.5646\n",
      "Epoch 15/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 1s/step - accuracy: 0.7881 - loss: 0.5504\n",
      "Epoch 16/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 2s/step - accuracy: 0.7965 - loss: 0.5379\n",
      "Epoch 17/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.7987 - loss: 0.5324\n",
      "Epoch 18/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 800ms/step - accuracy: 0.8122 - loss: 0.5044\n",
      "Epoch 19/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 679ms/step - accuracy: 0.8141 - loss: 0.4913\n",
      "Epoch 20/20\n",
      "\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 681ms/step - accuracy: 0.8231 - loss: 0.4778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 241ms/step - accuracy: 0.7982 - loss: 0.5173\n",
      "\n",
      "ğŸ“Œ **Test Accuracy:** 78.96%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "âœ… **Actual:** pracn  |  ğŸ”¥ **Predicted:** pbann\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "âœ… **Actual:** sgwqzp  |  ğŸ”¥ **Predicted:** pbbbp\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "âœ… **Actual:** srihzn  |  ğŸ”¥ **Predicted:** srinn\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "âœ… **Actual:** bgwia  |  ğŸ”¥ **Predicted:** bbwma\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "âœ… **Actual:** bbbsn  |  ğŸ”¥ **Predicted:** bbbnn\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, LSTM, Dense, TimeDistributed, Bidirectional, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "output_frames_path = \"output_frames\"\n",
    "img_size = (64, 64)  # Reduce image size\n",
    "max_sequence_length = 15  # Reduce sequence length\n",
    "\n",
    "# Load character mappings\n",
    "tokenizer = Tokenizer(filters=\"\", char_level=True, lower=True)\n",
    "tokenizer.fit_on_texts([\"abcdefghijklmnopqrstuvwxyz' \"])  # Define the vocabulary\n",
    "\n",
    "# Load preprocessed data using generator\n",
    "def data_generator(batch_size=16):\n",
    "    video_folders = os.listdir(output_frames_path)\n",
    "    while True:\n",
    "        np.random.shuffle(video_folders)\n",
    "        for i in range(0, len(video_folders), batch_size):\n",
    "            batch_videos = video_folders[i:i+batch_size]\n",
    "            X, y = [], []\n",
    "            for video_folder in batch_videos:\n",
    "                folder_path = os.path.join(output_frames_path, video_folder)\n",
    "                if not os.path.isdir(folder_path):\n",
    "                    continue\n",
    "\n",
    "                frames = []\n",
    "                for frame_file in sorted(os.listdir(folder_path)):\n",
    "                    if frame_file.endswith(\".jpg\"):\n",
    "                        frame = load_img(os.path.join(folder_path, frame_file), color_mode=\"grayscale\", target_size=img_size)\n",
    "                        frame = img_to_array(frame) / 255.0  # Normalize\n",
    "                        frames.append(frame)\n",
    "\n",
    "                if len(frames) == 0:\n",
    "                    continue  # Skip if no valid frames\n",
    "\n",
    "                word = video_folder.split(\"_\")[0].lower()  # Extract label from folder name\n",
    "                X.append(np.array(frames))\n",
    "                y.append(word)\n",
    "\n",
    "            if len(X) == 0:\n",
    "                continue  # Skip empty batches\n",
    "\n",
    "            X_padded = pad_sequences(X, maxlen=max_sequence_length, dtype=\"float32\", padding=\"post\", truncating=\"post\")\n",
    "            y_encoded = tokenizer.texts_to_sequences(y)\n",
    "            y_padded = pad_sequences(y_encoded, maxlen=max_sequence_length, dtype=\"int32\", padding=\"post\", truncating=\"post\")\n",
    "            y_categorical = to_categorical(y_padded, num_classes=len(tokenizer.word_index) + 1)\n",
    "\n",
    "            yield np.expand_dims(X_padded, axis=-1), y_categorical\n",
    "\n",
    "# Model Definition\n",
    "def build_model():\n",
    "    model = Sequential([\n",
    "        TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'), input_shape=(max_sequence_length, img_size[0], img_size[1], 1)),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "\n",
    "        TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same')),\n",
    "        TimeDistributed(MaxPooling2D((2, 2))),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "\n",
    "        TimeDistributed(Conv2D(128, (3, 3), activation='relu', padding='same')),\n",
    "        TimeDistributed(GlobalAveragePooling2D()),  # Replaces Flatten (lowers complexity)\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "\n",
    "        Bidirectional(LSTM(128, return_sequences=True, dropout=0.3)),\n",
    "        Bidirectional(LSTM(128, return_sequences=True, dropout=0.3)),\n",
    "\n",
    "        TimeDistributed(Dense(len(tokenizer.word_index) + 1, activation=\"softmax\"))\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.0005), metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Model Training\n",
    "batch_size = 16\n",
    "train_gen = data_generator(batch_size)\n",
    "model = build_model()\n",
    "history = model.fit(train_gen, steps_per_epoch=100, epochs=20)\n",
    "\n",
    "# Save model\n",
    "model.save(\"optimized_lip_reading_model.h5\")\n",
    "\n",
    "# Evaluate Model Accuracy\n",
    "test_gen = data_generator(batch_size)\n",
    "test_loss, test_acc = model.evaluate(test_gen, steps=10)\n",
    "print(f\"\\nğŸ“Œ **Test Accuracy:** {test_acc * 100:.2f}%\")\n",
    "\n",
    "# Predict Sample Words\n",
    "def predict_samples(num_samples=5):\n",
    "    test_gen = data_generator(batch_size=1)  # Single batch\n",
    "    for i in range(num_samples):\n",
    "        X_test, y_test = next(test_gen)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Convert predictions to text\n",
    "        pred_word = \"\".join([tokenizer.index_word.get(np.argmax(char), \"\") for char in y_pred[0]])\n",
    "        actual_word = \"\".join([tokenizer.index_word.get(np.argmax(char), \"\") for char in y_test[0]])\n",
    "\n",
    "        print(f\"âœ… **Actual:** {actual_word}  |  ğŸ”¥ **Predicted:** {pred_word}\")\n",
    "\n",
    "# Print 5 sample predictions\n",
    "predict_samples(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 75.60%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Paths\n",
    "output_frames_path = \"output_frames\"\n",
    "img_size = (64, 64)\n",
    "max_sequence_length = 15\n",
    "\n",
    "# Load tokenizer (same as used during training)\n",
    "tokenizer = Tokenizer(filters=\"\", char_level=True, lower=True)\n",
    "tokenizer.fit_on_texts([\"abcdefghijklmnopqrstuvwxyz' \"])  # Define the vocabulary\n",
    "\n",
    "# Function to load test data\n",
    "def load_test_data():\n",
    "    X_test, y_test = [], []\n",
    "    test_folders = os.listdir(output_frames_path)[:100]  # Load some test samples (adjust as needed)\n",
    "\n",
    "    for video_folder in test_folders:\n",
    "        folder_path = os.path.join(output_frames_path, video_folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        frames = []\n",
    "        for frame_file in sorted(os.listdir(folder_path)):\n",
    "            if frame_file.endswith(\".jpg\"):\n",
    "                frame = load_img(os.path.join(folder_path, frame_file), color_mode=\"grayscale\", target_size=img_size)\n",
    "                frame = img_to_array(frame) / 255.0  # Normalize\n",
    "                frames.append(frame)\n",
    "\n",
    "        word = video_folder.split(\"_\")[0].lower()  # Extract label from folder name\n",
    "        X_test.append(np.array(frames))\n",
    "        y_test.append(word)\n",
    "\n",
    "    X_padded = pad_sequences(X_test, maxlen=max_sequence_length, dtype=\"float32\", padding=\"post\", truncating=\"post\")\n",
    "    y_encoded = tokenizer.texts_to_sequences(y_test)\n",
    "    y_padded = pad_sequences(y_encoded, maxlen=max_sequence_length, dtype=\"int32\", padding=\"post\", truncating=\"post\")\n",
    "    \n",
    "    return np.expand_dims(X_padded, axis=-1), tf.keras.utils.to_categorical(y_padded, num_classes=len(tokenizer.word_index) + 1)\n",
    "\n",
    "# Load test data\n",
    "X_test, y_test_categorical = load_test_data()\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"optimized_lip_reading_model.h5\")\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_categorical, verbose=0)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"\\nTest Accuracy: {test_acc * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
